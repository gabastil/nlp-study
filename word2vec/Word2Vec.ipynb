{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       ".banner {\n",
       "    border-radius: 2px;\n",
       "    border-left: solid 5px gray;\n",
       "    padding-left: 1em;\n",
       "}\n",
       "\n",
       ".tip {\n",
       "    background: lightgreen;\n",
       "    border-left: solid 5px green;\n",
       "}\n",
       ".attention {\n",
       "    background: yellow;\n",
       "    border-left: solid 5px orange;\n",
       "}\n",
       "\n",
       ".warning {\n",
       "    background: orange;\n",
       "    border-left: solid 5px red;\n",
       "}\n",
       "\n",
       ".navigation {\n",
       "    font-size: 1.05em;\n",
       "    color: gray;\n",
       "}\n",
       "\n",
       ".navigation:hover {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".content {\n",
       "    font-size: 1.1em;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "HTML('''\n",
    "<style>\n",
    "\n",
    ".banner {\n",
    "    border-radius: 2px;\n",
    "    border-left: solid 5px gray;\n",
    "    padding-left: 1em;\n",
    "}\n",
    "\n",
    ".tip {\n",
    "    background: lightgreen;\n",
    "    border-left: solid 5px green;\n",
    "}\n",
    ".attention {\n",
    "    background: yellow;\n",
    "    border-left: solid 5px orange;\n",
    "}\n",
    "\n",
    ".warning {\n",
    "    background: orange;\n",
    "    border-left: solid 5px red;\n",
    "}\n",
    "\n",
    ".navigation {\n",
    "    font-size: 1.05em;\n",
    "    color: gray;\n",
    "}\n",
    "\n",
    ".navigation:hover {\n",
    "    color: black;\n",
    "}\n",
    "\n",
    ".content {\n",
    "    font-size: 1.1em;\n",
    "}\n",
    "</style>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation on Word2Vec\n",
    "Glenn Abastillas | 24 March, 2020\n",
    "\n",
    "``` ADD VISUAL OF KING - QUEEN = MAN WITH SVG ```\n",
    "\n",
    "This notebook goes over an example implementation of Word2Vec and some existing packages that perform Word2Vec training.\n",
    "\n",
    "Contents\n",
    "  1.  Preliminary Steps\n",
    "      * [Load Packages](#load_packages)\n",
    "      * [Preprocess Data](#preprocess_data)\n",
    "      * [Quick Background](#quick_background)\n",
    "  2. [Implementation from Scratch](#implementation_from_scratch)\n",
    "      * Word2Vec Flavors: Continuous Back of Words (CBOW) / Skip Grams (SG)\n",
    "      * Training\n",
    "      * Retrieving the trained matrix\n",
    "      * Applications\n",
    "  3. Using an Existing Package\n",
    "\n",
    "__At each step, we will also cover other packages that can be used to acheive the same thing (e.g., Countvectorizer)__\n",
    "  \n",
    "<p class='tip banner'>This is an example of a tip.<p>\n",
    "<p class='attention banner'>This is an example of an attention.<p>\n",
    "<p class='warning banner'>This is an example of a warning.<p>\n",
    "  \n",
    "---\n",
    "\n",
    "### Load Packages <a id=\"load_packages\"></a>\n",
    "First we import packages and clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "import tqdm\n",
    "from string import punctuation\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use data from the `gutenberg` corpus and normalize the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 438\n"
     ]
    }
   ],
   "source": [
    "sents = gutenberg.sents('blake-poems.txt')\n",
    "print(f'Number of sentences: {len(sents)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[insert navigation here]`\n",
    "\n",
    "---\n",
    "### Preprocess Data <a id=\"preprocess_data\"></a>\n",
    "##### Normalize Vocabulary\n",
    "\n",
    "To improve processing and richness of our lexical items, we normalize our language data. \n",
    "\n",
    "Normalizing data can involve a variety of tasks depending on the final application of our language model. These tasks including making all words the same case, removing punctuation, and removing **<a id=\"stopword\" style=\"text-decoration: none; cursor: help;\" title=\"Words that contribute little semantic information to a text\">stopwords</a>**.\n",
    "\n",
    "For this presentation, we will use **<a id=\"token\" style=\"text-decoration: none; cursor: help;\" title=\"Combinations of characters separated by spaces (e.g., words, numbers)\">tokens</a>** that are not punctuation nor stopwords.\n",
    "\n",
    "Let's quickly define some functions we will use to pare our text data down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_ = stopwords.words('english')\n",
    "\n",
    "def is_stopword(token):\n",
    "    ''' Check if a specified token is a stopword. '''\n",
    "    try:\n",
    "        return token.lower() in stopwords_\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def is_valid_token(token):\n",
    "    ''' Check if token is valid, i.e., not a stopword or punctuation '''\n",
    "    try:\n",
    "        return token.isalnum() & ~is_stopword(token)\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First Normalization Step\n",
    "Next, we create our `raw_text` data using the functions we just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences : 438\n",
      "CPU times: user 78.9 ms, sys: 6.55 ms, total: 85.5 ms\n",
      "Wall time: 89.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "normalized_sents = [[word.lower() for word in sent if is_valid_token(word)] for sent in sents]\n",
    "\n",
    "print(f'Number of sentences : {len(normalized_sents)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our `normalized_text`, we can create a `dict` to convert the strings into numbers for faster processing down the line. We also create maps for strings to integers, integers to strings, and a probability distribution of word frequencies for possible negative sampling (if there is time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1402\n"
     ]
    }
   ],
   "source": [
    "flattened_text = [word for sent in normalized_sents for word in sent]\n",
    "\n",
    "WORDS, COUNTS = np.unique(flattened_text, return_counts=True)\n",
    "\n",
    "PROBS = COUNTS**(3/4) / (COUNTS**(3/4)).sum()\n",
    "\n",
    "INDEX = np.arange(WORDS.size)\n",
    "\n",
    "VOCAB = dict(zip(WORDS, INDEX))\n",
    "VOCABR = dict(zip(INDEX, WORDS))\n",
    "\n",
    "print(f'Vocabulary size: {WORDS.size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Second Normalization Step\n",
    "\n",
    "Using the conversion function defined above, we can convert our `normalized_sents` into `data`, which contains only integers that will be used in our Word2Vec example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 9.06 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = (np.array([VOCAB[token] for token in sent]) for sent in normalized_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[insert navigation here]`\n",
    "\n",
    "---\n",
    "\n",
    "Use this reference for later [Dimensions greater than 300 have diminishing returns](https://www.aclweb.org/anthology/D14-1162/)\n",
    "\n",
    "### Quick Background <a id=\"quick_background\"></a>\n",
    "#### Background Into Word2Vec\n",
    "\n",
    "* What is it?\n",
    "  - <p class='content'>Quick definition (implementation of theoretical matrix bit): A method or representing words as numerical vectors, which allow us to improve the efficiency of our models as well as enable us to glean insight on how words behave in a text.</p>\n",
    "  - What is does to text: The Word2Vec model converts words as strings into an array of numbers of n-dimensions by training a shallow neural network and keeping only the trained weights.\n",
    "  - What the output is: The trained weights from the neural network we train are conveniently also act as the word vectors themselves in a matrix format.\n",
    "  \n",
    "* Why do we need it?\n",
    "  - Many uses in AI: Semantic analysis, entity discovery, lexical and lexical relationship analysis, and topic modeling.\n",
    "  - Pros: We can do algebra with words and converting strings to numeric vectors unlocks a host of abilities that we can perform on these numeric vectors.\n",
    "  - Cons: We need a large vocabulary and training can be very time and resources heavy.\n",
    " \n",
    "* What cool things can it do?\n",
    "  - Condense text into a lightweight matrix\n",
    "  - Provide semantic abilities\n",
    "  - Enable data to have algebraic properties\n",
    " \n",
    "* What are competing models?\n",
    "  - Other models to represent text\n",
    "  - GloVe\n",
    "  - Other vectorization models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[insert navigation here]`\n",
    "\n",
    "---\n",
    "## Implementation from Scratch <a id=\"implementation_from_scratch\"></a>\n",
    "\n",
    "For things example, we will create a Word2Vec language model using the data we preprocessed above. \n",
    "\n",
    "In this section, we will develop a **<a id=\"skip-gram\" style=\"text-decoration: none; cursor: help;\" title=\"Using the a token to predict its surroundings\">Skip-gram</a>** flavored Word2Vec model.\n",
    "\n",
    "We will:\n",
    "  * Create Skip-gram windows\n",
    "  * Create preliminary <a id='one-hot' style='text-decoration: none; cursor: help;' title='A vector that is comprised of zeros and ones indicating absence or presence of a value'>one-hot vectors</a>\n",
    "\n",
    "\n",
    "###### Parameters <a id='parameters'></a>\n",
    "First we define some hyperparameters that we use for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'window_size' : 2, 'dimensions' : 100, 'learning_rate' : 0.02, 'epochs' : 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "table, td, tr {\n",
    "    border: solid 1px gray;\n",
    "    background: green;\n",
    "}\n",
    "</style>\n",
    "This table quickly describes what each parameter does.\n",
    "\n",
    "Parameters | Data Type | Description\n",
    "--- | :-: | :--\n",
    "`window_size` | `int` | The number of target tokens before and after a central token to include\n",
    "`dimensions` | `int` | The number of dimensions in hidden layer. Dimensions greater than 300 have diminishing returns `[cite]`.\n",
    "`learning_rate` | `float` | How quickly our model will correct itself\n",
    "`epochs` | `int` | The number of rounds the model is trained\n",
    "\n",
    "##### Creating the Training Data <a id=\"creating_the_training_data\"></a>\n",
    "\n",
    "We will generate loose <a id='one-hot' style='text-decoration: none; cursor: help;' title='A vector that is comprised of zeros and ones indicating absence or presence of a value'>one-hot vectors</a> that will serve as input and target data when training our model.\n",
    "\n",
    "First we filter our data to ensure we have sufficient data to window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in data: 358\n",
      "CPU times: user 4.03 ms, sys: 832 µs, total: 4.86 ms\n",
      "Wall time: 4.57 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = [sent for sent in data if sent.size >= parameters['window_size'] + 1]\n",
    "\n",
    "print(f'Number of sentences in data: {len(data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we generate our one hot vectors using the `VOCAB` as a model for our vector.\n",
    "\n",
    "Let's define a few functions to help use generate these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datum = namedtuple('Datum', 'target context'.split())\n",
    "\n",
    "def one_hot(token, size=WORDS.size):\n",
    "    ''' Convert an input token into an integer according to a specified reference '''\n",
    "    vector = np.zeros((size, 1))\n",
    "    vector[token] = 1\n",
    "    return vector\n",
    "\n",
    "def process_sentence(sent, processed_sentence={}, window_size=parameters['window_size'] + 1):\n",
    "    ''' Return a dictionary with token keys and contexts as values\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            sent (list) : sentence to convert into one-hot vectors \n",
    "                          and group into target and context\n",
    "            processed_sentence (dict) : Previously processed sentences to add to\n",
    "            window_size (int) : Window size of CBOW\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            (dict) object with tokens as keys and their corresponding\n",
    "                   one-hot vector targets and context in the following format:\n",
    "            \n",
    "            >> { token : [[target, [context-1, context-2, ...]], ...]}\n",
    "    '''\n",
    "    for i, token in enumerate(sent):\n",
    "        a, b, j = max(i - window_size, 0), i + window_size, i+1\n",
    "        before, after = sent[a:i], sent[j:b]\n",
    "\n",
    "        context = []\n",
    "\n",
    "        # Loop through the surrounding tokens\n",
    "        for context_token in np.append(before, after):\n",
    "            try:\n",
    "                context.append(one_hot(context_token))\n",
    "            except:\n",
    "                print(token, context_token, a, b, before, after, sent[a:b])\n",
    "                raise\n",
    "        \n",
    "        if token in processed_sentence:\n",
    "            processed_sentence[token].context.append(context)\n",
    "        else:\n",
    "            target = one_hot(token)\n",
    "            processed_sentence[token] = Datum(target, [context])\n",
    "\n",
    "    return processed_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through all the sentences to generate `target` and `context` data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 358/358 [00:00<00:00, 1223.76it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_sentences = {}\n",
    "for sent in tqdm.tqdm(data):\n",
    "    processed_sentences = process_sentence(sent, processed_sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class='attention'>&uparrow; Processing time may vary </p>\n",
    "\n",
    "`[insert navigation here]`\n",
    "\n",
    "---\n",
    "##### Create Layers <a id='create_layers'></a>\n",
    "\n",
    "These matrices will serve as the layers that surround our `word2vec` layer during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions\n",
      "Weights 1 (1402, 100)\n",
      "Weights 2 (1402, 100)\n"
     ]
    }
   ],
   "source": [
    "weights_1 = np.random.random((WORDS.size, parameters['dimensions']))\n",
    "weights_2 = np.random.random((WORDS.size, parameters['dimensions']))\n",
    "print(f'Dimensions\\nWeights 1 {weights_1.shape}\\nWeights 2 {weights_2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[insert navigation here]`\n",
    "\n",
    "---\n",
    "###### Feed Forward Algorithm\n",
    "\n",
    "The first part of a two part algorithm defining a <a id='learning-step' style='text-decoration: none; cursor: help;' title='A phase where training data are learned and errors are adjusted throughout the model'>learning step</a>. This algorithm introduces our randomly initialized model to its first evidence of real data to learn from. It then predicts a surrounding vocabulary item from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(datum):\n",
    "    ''' Return the an array normalized to a probability '''\n",
    "    e = np.exp(datum - datum.max())\n",
    "    return e / e.sum()\n",
    "\n",
    "def forward(datum, weights_1=weights_1, weights_2=weights_2):\n",
    "    ''' Return three matrices corresponding to the prediction, hidden layer, and output '''\n",
    "    hidden = np.dot(weights_1.T, datum)\n",
    "    output = np.dot(weights_2, hidden)\n",
    "    prediction = softmax(output)\n",
    "    return prediction, hidden, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[insert navigation here]`\n",
    "\n",
    "---\n",
    "###### Backpropagation Algorithm\n",
    "\n",
    "The second part of the two part algorithm defining a <a id='learning-step' style='text-decoration: none; cursor: help;' title='A phase where training data are learned and errors are adjusted throughout the model'>learning step</a>. This algorithm compares the output of the <a id='feed-forward-algorithm' style='text-decoration: none; cursor: help;' title='The algorithm that takes in new data and attempts to make predictions from it'>feed forward algorithm</a> to the input token's actual context, calculates the error, and adjusts the model to correct for it. The adjustments are made in increments set by the learning rate parameter we set in our `parameters` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(prediction, context):\n",
    "    ''' Return a weights with the summed prediction error '''\n",
    "    error = np.zeros((prediction.size, 1))\n",
    "    for subcontext in context:\n",
    "        for token in subcontext:\n",
    "            error += prediction - token\n",
    "    return error\n",
    "\n",
    "def backpropagate(prediction, hidden, target, context, weights_1=weights_1, weights_2=weights_2, index=INDEX):\n",
    "    ''' Update weight matrices according to output from forward() '''\n",
    "    error = calculate_error(prediction, context)\n",
    "\n",
    "    sample = negative_sample(context)\n",
    "    target_index = index[target.flatten() == 1]\n",
    "    sample = np.append(target_index, sample)\n",
    "    error[~sample] = 0\n",
    "    \n",
    "    weights_2_delta = np.outer(error, hidden)\n",
    "    hidden_error = np.dot(weights_2.T, error)\n",
    "    weights_1_delta = np.outer(hidden_error, target).T\n",
    "    \n",
    "    weights_1 -= weights_1_delta * parameters['learning_rate']\n",
    "    weights_2 -= weights_2_delta * parameters['learning_rate']\n",
    "    \n",
    "def negative_sample(context, n=5, index=INDEX, probs=PROBS):\n",
    "    ''' Return an array of randomly sampled tokens to be updated '''\n",
    "    positives = sum([sum(c) for c in context]).flatten() >= 1\n",
    "    negatives = np.invert(positives)\n",
    "    sample = index[negatives]\n",
    "    p = probs[negatives] / probs[negatives].sum()\n",
    "    return np.random.choice(sample, n, p=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sandbox to do negative_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = processed_sentences[1]\n",
    "target, context = example.target, example.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, h, u = forward(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "backpropagate(pred, h, target, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[insert navigation here]`\n",
    "\n",
    "---\n",
    "##### Training Algorithm\n",
    "\n",
    "Having both the feed forward and backpropagation algorithms defined, we can now define a training algorithm to learn all training examples for a single <a id='epoch' style='text-decoration: none; cursor: help;' title='A complete cycle of learning steps through all training data'>epoch</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_data, weights_1=weights_1, weights_2=weights_2, parameters=parameters, total=WORDS.size):\n",
    "    ''' Train the Word2Vec model on our training data to generate meaningful word vectors '''\n",
    "    \n",
    "    data = tqdm.tqdm(training_data.items())\n",
    "\n",
    "    for epoch in tqdm.trange(50):\n",
    "        for __, (target, context) in data:\n",
    "#         for __, (target, context) in tqdm.trange(data, total = len(data)):\n",
    "            prediction, hidden, output = forward(target)\n",
    "            backpropagate(prediction, hidden, target, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[insert navigation here]`\n",
    "\n",
    "---\n",
    "###### Test Iteration <a id='test_iteration'></a>\n",
    "\n",
    "This cell loops through all our training data to demonstrate what happens in one training <a id='epoch' style='text-decoration: none; cursor: help;' title='A complete cycle of learning steps through all training data'>epoch</a>.\n",
    "\n",
    "<p class='warning'>Processing time may vary</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1384 [00:00<?, ?it/s]\n",
      " 98%|█████████▊| 1355/1384 [00:04<00:00, 336.85it/s]\n",
      "100%|██████████| 1384/1384 [00:04<00:00, 322.60it/s]\n",
      "100%|██████████| 50/50 [03:21<00:00,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 3s, sys: 16.7 s, total: 3min 20s\n",
      "Wall time: 3min 21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(processed_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Looking at Some Examples\n",
    "\n",
    "We define some functions to inspect the output of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(token, model=weights_1):\n",
    "    ''' Return the word vector corresponding to a token '''\n",
    "    return model[token]\n",
    "\n",
    "def similarity(vector1, vector2):\n",
    "    ''' Return the cosine similarity score for two tokens input as vectors '''\n",
    "    if isinstance(vector1, int):\n",
    "        vector1 = word_vector(vector1)\n",
    "        \n",
    "    if isinstance(vector2, int):\n",
    "        vector2 = word_vector(vector2)\n",
    "        \n",
    "    a = np.dot(vector1, vector2)\n",
    "    b = np.dot(vector1, vector1)\n",
    "    c = np.dot(vector2, vector2)\n",
    "    return a / (np.sqrt(b) * np.sqrt(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We inspect randomly selected words for their similarity score where $similarity \\in [-1,1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increase and sick\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.9999999999999999"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = np.random.randint(0, WORDS.size)\n",
    "v2 = np.random.randint(0, WORDS.size)\n",
    "print(f'{VOCABR[v1]} and {VOCABR[v2]}')\n",
    "similarity(v1, v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the current model trained only on a single epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token number 1194 is \"terror\" along with \"terrific\" with cos score as 0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "token = np.random.randint(0, WORDS.size)\n",
    "a, b = weights_1[token - 1], weights_1[token]\n",
    "distance = np.dot(a,b) / (np.sqrt(np.dot(a, a)) * np.sqrt(np.dot(b,b)))\n",
    "\n",
    "print(f'Token number {token} is \"{VOCABR[token]}\" along with \"{VOCABR[token-1]}\" with cos score as {distance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('20200326_blake-poems.csv', weights_1, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[insert navigation here]`\n",
    "\n",
    "---\n",
    "#### Using Our Trained Model\n",
    "\n",
    "We can use our trained model to `list things we can do with our Word2Vec model from earlier`.\n",
    "\n",
    "First, we define functions to help do those things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(token, model=weights_1):\n",
    "    ''' Return the token and vector of the most similar token in the model to input token '''\n",
    "    best_score = -1\n",
    "    token_vector = word_vector(token)\n",
    "    best_vector = None\n",
    "    for i, current_vector in enumerate(model):\n",
    "        if i == token:\n",
    "            continue\n",
    "            \n",
    "        score = similarity(token_vector, current_vector)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_vector = i\n",
    "    return best_vector, best_score\n",
    "\n",
    "\n",
    "def topn(token, n=3, model=weights_1):\n",
    "    ''' Return the top n tokens and vectors most closely related to input token '''\n",
    "    \n",
    "    similarity_scores, vectors = [], []\n",
    "    token_vector = word_vector(token, model)\n",
    "    \n",
    "    for i, current_vector in enumerate(model):\n",
    "        score = similarity(token_vector, current_vector)\n",
    "        \n",
    "        if similarity_scores and similarity_scores[0] < score:\n",
    "            similarity_scores.insert(0, score)\n",
    "            vectors.insert(0, i)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with algebraic interactions of this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar(994)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCABR[994], VOCABR[8066]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity(word_vector(343), word_vector(344)), VOCABR[343], VOCABR[344]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x11d8e4c50>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(weights_1[:,1], weights_1[:,62])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector.shape, matrix_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, h, u = forward(vector, matrix_1, matrix_2)\n",
    "pred.shape, h.shape, u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCABR[vector.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCABR[pred.argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using an Existing Package\n",
    "\n",
    "There are existing implementations that already exist that allow you to use Word2Vec technology out of the box.\n",
    "\n",
    "Examples of these include:\n",
    "  * SpaCy\n",
    "  * gensim\n",
    "  * ELMo\n",
    "  * fasttext\n",
    " \n",
    " \n",
    "### SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
