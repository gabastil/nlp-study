{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Train Test Study\n",
    "---\n",
    "Glenn Abastillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Embedding, LSTM, Flatten, Reshape\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.datasets import imdb\n",
    "\n",
    "from nltk.corpus import brown\n",
    "\n",
    "from lxml import etree\n",
    "import requests\n",
    "import numpy as np\n",
    "from io import StringIO, BytesIO\n",
    "\n",
    "corpus = [[_.lower() for _ in sent if _.isalnum()] for sent in brown.sents('cp05')]\n",
    "url = \"http://www.binisaya.com/node/3219\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "data = tokenizer.texts_to_sequences(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_length = [len(_) for _ in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = pad_sequences(data, maxlen=max(sent_length), padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### Cebuano Data\n",
    "Get data from online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = etree.parse(StringIO(results.text), parser=etree.HTMLParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = site.xpath(\"//*[text() and (not(starts-with(text(), '<')) and not(starts-with(text(), '\\n')))]/text()\")\n",
    "paras = site.xpath(\"//p[text() and (not(starts-with(text(), '<')) and not(starts-with(text(), '\\n')))]/text()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras_ = [[w.lower() for w in sent.split() if w.isalnum()] for line in paras for sent in line.split(\".\")]\n",
    "cebuano = [_ for _ in paras_ if _]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mga aduna koy maayong isugid kaninyo mahitungod ani bago nako nasaksihan nga maayong kapangwartahan', 'kini mao ang buzzbreak app', 'unsay paagi aron', '1', 'i download ra nimo cya sa google app store o kaha sa apple app store', '2', 'dayun mag himo ka ug account', 'duha ang paagi', 'pwede ka mag gamit sa imong facebook o kaha sa imong gmail account', '3', 'daghang paagi makakuha ug puntos o points', 'kini puntos sama ra sa kwarta nga imong nakulekta', 'usa sa paagi ang pag check in kada adlaw', 'pagbasa ug mga balita', 'paglantaw ug mga bidyo', 'ug daghan pa', '4', 'maka withdraw ka pina agi sa gcash o kaha sa paypal', 'ang pinaka ubos nimo nga mawithdraw kay usa ka piso', 'buot ipasabot nga di na ka kinahanglang magtigom pa ug gatos para lang maka withdraw', '5', 'duna sad koy gasa nimo nga puntos karon kung buot nimong kuhaon', 'sayon lang ang paagi', 'ig human nimo ug download', 'comment lang aron mahatagan tka sa puntos nga akong igasa nimo', 'para sa detalyado nga pahina mahitungod aning buzzbreak pwede ka mubasa ngari']\n"
     ]
    }
   ],
   "source": [
    "print([' '.join(_) for _ in cebuano])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebuano_y = np.array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(cebuano)\n",
    "cebuano_ = tokenizer.texts_to_sequences(cebuano)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebuano_ = pad_sequences(cebuano_, maxlen=15, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_word = {word: idx for idx, word in tokenizer.word_index.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Develop Model\n",
    "\n",
    "Define X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cebuano_\n",
    "y = cebuano_y\n",
    "vocab_size = len(to_word) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create series + targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 5\n",
    "series = []\n",
    "flattened = X.flatten()\n",
    "for i, token in enumerate(flattened):\n",
    "    p = max(0, i - window)\n",
    "    prev = X.flatten()[p:i]\n",
    "    series.append((to_categorical(token, vocab_size), prev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets, context = zip(*series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = pad_sequences(context, 5, padding='post')\n",
    "targets = np.array(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = Input((1,5), name='Input')\n",
    "\n",
    "# E = Embedding(vocab_size, 100, name='embedding', input_shape=(15,))(I)\n",
    "L = LSTM(128)(I)\n",
    "K = Dense(100, activation='relu')(L)\n",
    "D = Dense(vocab_size, activation='sigmoid', name='output')(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 1, 5)              0         \n",
      "_________________________________________________________________\n",
      "lstm_35 (LSTM)               (None, 128)               68608     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 109)               11009     \n",
      "=================================================================\n",
      "Total params: 92,517\n",
      "Trainable params: 92,517\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=I, outputs=D, name='model')\n",
    "model.compile('rmsprop', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "390/390 [==============================] - 3s 8ms/step - loss: 4.5675 - acc: 0.4692\n",
      "Epoch 2/50\n",
      "390/390 [==============================] - 0s 273us/step - loss: 4.3473 - acc: 0.5385\n",
      "Epoch 3/50\n",
      "390/390 [==============================] - 0s 247us/step - loss: 4.1058 - acc: 0.5385\n",
      "Epoch 4/50\n",
      "390/390 [==============================] - 0s 198us/step - loss: 3.7753 - acc: 0.5385\n",
      "Epoch 5/50\n",
      "390/390 [==============================] - 0s 198us/step - loss: 3.4323 - acc: 0.5385\n",
      "Epoch 6/50\n",
      "390/390 [==============================] - 0s 197us/step - loss: 3.1884 - acc: 0.5385\n",
      "Epoch 7/50\n",
      "390/390 [==============================] - 0s 202us/step - loss: 3.0332 - acc: 0.5385\n",
      "Epoch 8/50\n",
      "390/390 [==============================] - 0s 230us/step - loss: 2.9130 - acc: 0.5385\n",
      "Epoch 9/50\n",
      "390/390 [==============================] - 0s 199us/step - loss: 2.8027 - acc: 0.5385\n",
      "Epoch 10/50\n",
      "390/390 [==============================] - 0s 198us/step - loss: 2.6941 - acc: 0.5385\n",
      "Epoch 11/50\n",
      "390/390 [==============================] - 0s 194us/step - loss: 2.5943 - acc: 0.5385\n",
      "Epoch 12/50\n",
      "390/390 [==============================] - 0s 201us/step - loss: 2.4966 - acc: 0.5385\n",
      "Epoch 13/50\n",
      "390/390 [==============================] - 0s 203us/step - loss: 2.3875 - acc: 0.5385\n",
      "Epoch 14/50\n",
      "390/390 [==============================] - 0s 200us/step - loss: 2.2811 - acc: 0.5385\n",
      "Epoch 15/50\n",
      "390/390 [==============================] - 0s 205us/step - loss: 2.1694 - acc: 0.5385\n",
      "Epoch 16/50\n",
      "390/390 [==============================] - 0s 199us/step - loss: 2.0617 - acc: 0.5385\n",
      "Epoch 17/50\n",
      "390/390 [==============================] - 0s 206us/step - loss: 1.9546 - acc: 0.5385\n",
      "Epoch 18/50\n",
      "390/390 [==============================] - 0s 202us/step - loss: 1.8602 - acc: 0.5385\n",
      "Epoch 19/50\n",
      "390/390 [==============================] - 0s 199us/step - loss: 1.7749 - acc: 0.5385\n",
      "Epoch 20/50\n",
      "390/390 [==============================] - 0s 204us/step - loss: 1.7043 - acc: 0.5385\n",
      "Epoch 21/50\n",
      "390/390 [==============================] - 0s 267us/step - loss: 1.6513 - acc: 0.5385\n",
      "Epoch 22/50\n",
      "390/390 [==============================] - 0s 231us/step - loss: 1.6055 - acc: 0.5385\n",
      "Epoch 23/50\n",
      "390/390 [==============================] - 0s 204us/step - loss: 1.5688 - acc: 0.5385\n",
      "Epoch 24/50\n",
      "390/390 [==============================] - 0s 206us/step - loss: 1.5329 - acc: 0.5385\n",
      "Epoch 25/50\n",
      "390/390 [==============================] - 0s 296us/step - loss: 1.5017 - acc: 0.5385\n",
      "Epoch 26/50\n",
      "390/390 [==============================] - 0s 282us/step - loss: 1.4725 - acc: 0.5385\n",
      "Epoch 27/50\n",
      "390/390 [==============================] - 0s 285us/step - loss: 1.4472 - acc: 0.5385\n",
      "Epoch 28/50\n",
      "390/390 [==============================] - 0s 206us/step - loss: 1.4188 - acc: 0.5385\n",
      "Epoch 29/50\n",
      "390/390 [==============================] - 0s 227us/step - loss: 1.3862 - acc: 0.5385\n",
      "Epoch 30/50\n",
      "390/390 [==============================] - 0s 194us/step - loss: 1.3543 - acc: 0.5487\n",
      "Epoch 31/50\n",
      "390/390 [==============================] - 0s 264us/step - loss: 1.3046 - acc: 0.5692\n",
      "Epoch 32/50\n",
      "390/390 [==============================] - 0s 241us/step - loss: 1.2576 - acc: 0.5923\n",
      "Epoch 33/50\n",
      "390/390 [==============================] - 0s 295us/step - loss: 1.2192 - acc: 0.5949\n",
      "Epoch 34/50\n",
      "390/390 [==============================] - 0s 237us/step - loss: 1.1739 - acc: 0.6282\n",
      "Epoch 35/50\n",
      "390/390 [==============================] - 0s 251us/step - loss: 1.1372 - acc: 0.6744\n",
      "Epoch 36/50\n",
      "390/390 [==============================] - 0s 254us/step - loss: 1.0993 - acc: 0.6949\n",
      "Epoch 37/50\n",
      "390/390 [==============================] - 0s 268us/step - loss: 1.0727 - acc: 0.7051\n",
      "Epoch 38/50\n",
      "390/390 [==============================] - 0s 263us/step - loss: 1.0404 - acc: 0.7128\n",
      "Epoch 39/50\n",
      "390/390 [==============================] - 0s 253us/step - loss: 1.0108 - acc: 0.7205\n",
      "Epoch 40/50\n",
      "390/390 [==============================] - 0s 265us/step - loss: 0.9959 - acc: 0.7231\n",
      "Epoch 41/50\n",
      "390/390 [==============================] - 0s 251us/step - loss: 0.9675 - acc: 0.7436\n",
      "Epoch 42/50\n",
      "390/390 [==============================] - 0s 235us/step - loss: 0.9486 - acc: 0.7436\n",
      "Epoch 43/50\n",
      "390/390 [==============================] - 0s 232us/step - loss: 0.9270 - acc: 0.7692\n",
      "Epoch 44/50\n",
      "390/390 [==============================] - 0s 236us/step - loss: 0.9170 - acc: 0.7692\n",
      "Epoch 45/50\n",
      "390/390 [==============================] - 0s 233us/step - loss: 0.8976 - acc: 0.7769\n",
      "Epoch 46/50\n",
      "390/390 [==============================] - 0s 238us/step - loss: 0.8830 - acc: 0.7795\n",
      "Epoch 47/50\n",
      "390/390 [==============================] - 0s 245us/step - loss: 0.8614 - acc: 0.7949\n",
      "Epoch 48/50\n",
      "390/390 [==============================] - 0s 258us/step - loss: 0.8479 - acc: 0.7872\n",
      "Epoch 49/50\n",
      "390/390 [==============================] - 0s 272us/step - loss: 0.8411 - acc: 0.8000\n",
      "Epoch 50/50\n",
      "390/390 [==============================] - 0s 259us/step - loss: 0.8231 - acc: 0.8026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13700fc88>"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(context.reshape(390, 1, 5), targets, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lstm-1.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Generate Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.choice(X[X != 0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.zeros(5)\n",
    "arr[0] = seed\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(arr.reshape(1, 1, 5)).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
