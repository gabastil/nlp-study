{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras CNN Train Test Study\n",
    "----\n",
    "Glenn Abastillas\n",
    "\n",
    "This notebook provides an example of training a CNN to identify images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPool2D, Conv3D, MaxPool3D\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Random Selection of Fashion Items')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 8, figsize=(20, 5))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    current = random.randint(0, x_train.shape[0])\n",
    "    ax.imshow(x_train[current], cmap='gray')\n",
    "    ax.set_title(f'class {y_train[current]}', fontdict={'fontsize': 20})\n",
    "    ax.set_yticks([])\n",
    "\n",
    "fig.suptitle(\"Random Selection of Fashion Items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 1, *x_train.shape[1:])\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, *x_test.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Conv2D in module keras.layers.convolutional:\n",
      "\n",
      "class Conv2D(_Conv)\n",
      " |  2D convolution layer (e.g. spatial convolution over images).\n",
      " |  \n",
      " |  This layer creates a convolution kernel that is convolved\n",
      " |  with the layer input to produce a tensor of\n",
      " |  outputs. If `use_bias` is True,\n",
      " |  a bias vector is created and added to the outputs. Finally, if\n",
      " |  `activation` is not `None`, it is applied to the outputs as well.\n",
      " |  \n",
      " |  When using this layer as the first layer in a model,\n",
      " |  provide the keyword argument `input_shape`\n",
      " |  (tuple of integers, does not include the sample axis),\n",
      " |  e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n",
      " |  in `data_format=\"channels_last\"`.\n",
      " |  \n",
      " |  # Arguments\n",
      " |      filters: Integer, the dimensionality of the output space\n",
      " |          (i.e. the number of output filters in the convolution).\n",
      " |      kernel_size: An integer or tuple/list of 2 integers, specifying the\n",
      " |          height and width of the 2D convolution window.\n",
      " |          Can be a single integer to specify the same value for\n",
      " |          all spatial dimensions.\n",
      " |      strides: An integer or tuple/list of 2 integers,\n",
      " |          specifying the strides of the convolution\n",
      " |          along the height and width.\n",
      " |          Can be a single integer to specify the same value for\n",
      " |          all spatial dimensions.\n",
      " |          Specifying any stride value != 1 is incompatible with specifying\n",
      " |          any `dilation_rate` value != 1.\n",
      " |      padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
      " |          Note that `\"same\"` is slightly inconsistent across backends with\n",
      " |          `strides` != 1, as described\n",
      " |          [here](https://github.com/keras-team/keras/pull/9473#issuecomment-372166860)\n",
      " |      data_format: A string,\n",
      " |          one of `\"channels_last\"` or `\"channels_first\"`.\n",
      " |          The ordering of the dimensions in the inputs.\n",
      " |          `\"channels_last\"` corresponds to inputs with shape\n",
      " |          `(batch, height, width, channels)` while `\"channels_first\"`\n",
      " |          corresponds to inputs with shape\n",
      " |          `(batch, channels, height, width)`.\n",
      " |          It defaults to the `image_data_format` value found in your\n",
      " |          Keras config file at `~/.keras/keras.json`.\n",
      " |          If you never set it, then it will be \"channels_last\".\n",
      " |      dilation_rate: an integer or tuple/list of 2 integers, specifying\n",
      " |          the dilation rate to use for dilated convolution.\n",
      " |          Can be a single integer to specify the same value for\n",
      " |          all spatial dimensions.\n",
      " |          Currently, specifying any `dilation_rate` value != 1 is\n",
      " |          incompatible with specifying any stride value != 1.\n",
      " |      activation: Activation function to use\n",
      " |          (see [activations](../activations.md)).\n",
      " |          If you don't specify anything, no activation is applied\n",
      " |          (ie. \"linear\" activation: `a(x) = x`).\n",
      " |      use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |      kernel_initializer: Initializer for the `kernel` weights matrix\n",
      " |          (see [initializers](../initializers.md)).\n",
      " |      bias_initializer: Initializer for the bias vector\n",
      " |          (see [initializers](../initializers.md)).\n",
      " |      kernel_regularizer: Regularizer function applied to\n",
      " |          the `kernel` weights matrix\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      bias_regularizer: Regularizer function applied to the bias vector\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      activity_regularizer: Regularizer function applied to\n",
      " |          the output of the layer (its \"activation\").\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      kernel_constraint: Constraint function applied to the kernel matrix\n",
      " |          (see [constraints](../constraints.md)).\n",
      " |      bias_constraint: Constraint function applied to the bias vector\n",
      " |          (see [constraints](../constraints.md)).\n",
      " |  \n",
      " |  # Input shape\n",
      " |      4D tensor with shape:\n",
      " |      `(samples, channels, rows, cols)`\n",
      " |      if `data_format` is `\"channels_first\"`\n",
      " |      or 4D tensor with shape:\n",
      " |      `(samples, rows, cols, channels)`\n",
      " |      if `data_format` is `\"channels_last\"`.\n",
      " |  \n",
      " |  # Output shape\n",
      " |      4D tensor with shape:\n",
      " |      `(samples, filters, new_rows, new_cols)`\n",
      " |      if `data_format` is `\"channels_first\"`\n",
      " |      or 4D tensor with shape:\n",
      " |      `(samples, new_rows, new_cols, filters)`\n",
      " |      if `data_format` is `\"channels_last\"`.\n",
      " |      `rows` and `cols` values might have changed due to padding.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Conv2D\n",
      " |      _Conv\n",
      " |      keras.engine.base_layer.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _Conv:\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the layer weights.\n",
      " |      \n",
      " |      Must be implemented on all layers that have weights.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Keras tensor (future input to layer)\n",
      " |              or list/tuple of Keras tensors to reference\n",
      " |              for weight shape computations.\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, **kwargs)\n",
      " |      Wrapper around self.call(), for handling internal references.\n",
      " |      \n",
      " |      If a Keras tensor is passed:\n",
      " |          - We call self._add_inbound_node().\n",
      " |          - If necessary, we `build` the layer to match\n",
      " |              the _keras_shape of the input(s).\n",
      " |          - We update the _keras_shape of every input tensor with\n",
      " |              its new shape (obtained via self.compute_output_shape).\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |          - We update the _keras_history of the output tensor(s)\n",
      " |              with the current layer.\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Can be a tensor or list/tuple of tensors.\n",
      " |          **kwargs: Additional keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output of the layer's `call` method.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case the layer is missing shape information\n",
      " |              for its `build` call.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Adds losses to the layer.\n",
      " |      \n",
      " |      The loss may potentially be conditional on some inputs tensors,\n",
      " |      for instance activity losses are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          losses: loss tensor or list of loss tensors\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the losses as conditional on these inputs.\n",
      " |              If None is passed, the loss is assumed unconditional\n",
      " |              (e.g. L2 weight regularization, which only depends\n",
      " |              on the layer's weights variables, not on any inputs tensors).\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Adds updates to the layer.\n",
      " |      \n",
      " |      The updates may potentially be conditional on some inputs tensors,\n",
      " |      for instance batch norm updates are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          updates: update op or list of update ops\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the updates as conditional on these inputs.\n",
      " |              If None is passed, the updates are assumed unconditional.\n",
      " |  \n",
      " |  add_weight(self, name, shape, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)\n",
      " |      Adds a weight variable to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, the name for the weight variable.\n",
      " |          shape: The shape tuple of the weight.\n",
      " |          dtype: The dtype of the weight.\n",
      " |          initializer: An Initializer instance (callable).\n",
      " |          regularizer: An optional Regularizer instance.\n",
      " |          trainable: A boolean, whether the weight should\n",
      " |              be trained via backprop or not (assuming\n",
      " |              that the layer itself is also trainable).\n",
      " |          constraint: An optional Constraint instance.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The created weight variable.\n",
      " |  \n",
      " |  assert_input_compatibility(self, inputs)\n",
      " |      Checks compatibility between the layer and provided inputs.\n",
      " |      \n",
      " |      This checks that the tensor(s) `input`\n",
      " |      verify the input assumptions of the layer\n",
      " |      (if any). If not, exceptions are raised.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of mismatch between\n",
      " |              the provided inputs and the expectations of the layer.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      # Returns\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Counts the total number of scalars composing the weights.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An integer count.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the layer isn't yet built\n",
      " |              (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  built\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input shape tuple\n",
      " |          (or list of input shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  losses\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output tensor or list of output tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one inbound node,\n",
      " |      or if all inbound nodes have the same output shape.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output shape tuple\n",
      " |          (or list of input shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  weights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Conv2D); Conv2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28))`\n",
      "  \n",
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "layers = [\n",
    "    Conv2D(32, 3, 3, activation='relu', input_shape=(28, 28)),\n",
    "    Conv2D(32, 3, 3, activation='relu'),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The `kernel_size` argument must be a tuple of 3 integers. Received: (3, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-317adbef34a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m    613\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rank, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kernel_size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'strides'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/keras/utils/conv_utils.py\u001b[0m in \u001b[0;36mnormalize_tuple\u001b[0;34m(value, n, name)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_tuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             raise ValueError('The `' + name + '` argument must be a tuple of ' +\n\u001b[0;32m---> 39\u001b[0;31m                              str(n) + ' integers. Received: ' + str(value))\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msingle_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue_tuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The `kernel_size` argument must be a tuple of 3 integers. Received: (3, 3)"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv3D(32, (3, 3), activation='relu', input_shape=(1, 28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv2d_10: expected ndim=4, found ndim=3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3e944e780e03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                     \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv2d_10: expected ndim=4, found ndim=3"
     ]
    }
   ],
   "source": [
    "model = Sequential(layers=layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
