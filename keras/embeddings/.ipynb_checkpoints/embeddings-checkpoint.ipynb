{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings Study\n",
    "---\n",
    "Glenn Abastillas\n",
    "\n",
    "Creating word embeddings with a single layer neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from nltk.corpus import brown\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'cp02'\n",
    "corpus = [w for w in brown.words(text) if w.isalnum()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(corpus)\n",
    "word = dict(enumerate(vocab))\n",
    "index = {b: a for a, b in word.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [index[w] for w in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get target and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(data)\n",
    "window = 3\n",
    "bag = []\n",
    "\n",
    "for i, w in enumerate(data):\n",
    "    a, b, c = max(i - window, 0), i + 1, min(i + 1 + window, size)\n",
    "    \n",
    "    x = [(w, t) for t in data[a:i] + data[b:c]]\n",
    "    bag.extend(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert target and context into one hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = max(data) + 1\n",
    "X, y = [], []\n",
    "\n",
    "for (x, y_) in bag:\n",
    "    x = to_categorical(x, vocab_size)\n",
    "    y_ = to_categorical(y_, vocab_size)\n",
    "    X.append(x)\n",
    "    y.append(y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11832, 723)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Input(shape=(X.shape[1],))\n",
    "B = Dense(723)(A)\n",
    "C = Activation('softmax')(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=A, outputs=C)\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11832/11832 [==============================] - 5s 414us/step - loss: 6.2943 - acc: 0.0665\n",
      "Epoch 2/50\n",
      "11832/11832 [==============================] - 4s 373us/step - loss: 6.0749 - acc: 0.0794\n",
      "Epoch 3/50\n",
      "11832/11832 [==============================] - 5s 385us/step - loss: 5.8805 - acc: 0.0851\n",
      "Epoch 4/50\n",
      "11832/11832 [==============================] - 4s 370us/step - loss: 5.7067 - acc: 0.0855\n",
      "Epoch 5/50\n",
      "11832/11832 [==============================] - 5s 386us/step - loss: 5.5543 - acc: 0.0871\n",
      "Epoch 6/50\n",
      "11832/11832 [==============================] - 4s 370us/step - loss: 5.4222 - acc: 0.0876\n",
      "Epoch 7/50\n",
      "11832/11832 [==============================] - 4s 377us/step - loss: 5.3089 - acc: 0.0889\n",
      "Epoch 8/50\n",
      "11832/11832 [==============================] - 4s 371us/step - loss: 5.2117 - acc: 0.0911\n",
      "Epoch 9/50\n",
      "11832/11832 [==============================] - 4s 377us/step - loss: 5.1278 - acc: 0.0932\n",
      "Epoch 10/50\n",
      "11832/11832 [==============================] - 5s 390us/step - loss: 5.0543 - acc: 0.0941\n",
      "Epoch 11/50\n",
      "11832/11832 [==============================] - 5s 388us/step - loss: 4.9887 - acc: 0.0949\n",
      "Epoch 12/50\n",
      "11832/11832 [==============================] - 5s 404us/step - loss: 4.9290 - acc: 0.0957\n",
      "Epoch 13/50\n",
      "11832/11832 [==============================] - 4s 380us/step - loss: 4.8737 - acc: 0.0973\n",
      "Epoch 14/50\n",
      "11832/11832 [==============================] - 4s 373us/step - loss: 4.8218 - acc: 0.0990\n",
      "Epoch 15/50\n",
      "11832/11832 [==============================] - 4s 376us/step - loss: 4.7728 - acc: 0.1007\n",
      "Epoch 16/50\n",
      "11832/11832 [==============================] - 5s 381us/step - loss: 4.7261 - acc: 0.1017\n",
      "Epoch 17/50\n",
      "11832/11832 [==============================] - 5s 381us/step - loss: 4.6814 - acc: 0.1029\n",
      "Epoch 18/50\n",
      "11832/11832 [==============================] - 5s 388us/step - loss: 4.6385 - acc: 0.1036\n",
      "Epoch 19/50\n",
      "11832/11832 [==============================] - 5s 398us/step - loss: 4.5971 - acc: 0.1041\n",
      "Epoch 20/50\n",
      "11832/11832 [==============================] - 5s 421us/step - loss: 4.5572 - acc: 0.1056\n",
      "Epoch 21/50\n",
      "11832/11832 [==============================] - 5s 460us/step - loss: 4.5187 - acc: 0.1065\n",
      "Epoch 22/50\n",
      "11832/11832 [==============================] - 6s 514us/step - loss: 4.4814 - acc: 0.1072\n",
      "Epoch 23/50\n",
      "11832/11832 [==============================] - 6s 492us/step - loss: 4.4453 - acc: 0.1084\n",
      "Epoch 24/50\n",
      "11832/11832 [==============================] - 6s 503us/step - loss: 4.4105 - acc: 0.1084\n",
      "Epoch 25/50\n",
      "11832/11832 [==============================] - 5s 384us/step - loss: 4.3766 - acc: 0.1093\n",
      "Epoch 26/50\n",
      "11832/11832 [==============================] - 5s 393us/step - loss: 4.3438 - acc: 0.1103\n",
      "Epoch 27/50\n",
      "11832/11832 [==============================] - 5s 405us/step - loss: 4.3119 - acc: 0.1099\n",
      "Epoch 28/50\n",
      "11832/11832 [==============================] - 5s 454us/step - loss: 4.2811 - acc: 0.1094\n",
      "Epoch 29/50\n",
      "11832/11832 [==============================] - 6s 477us/step - loss: 4.2512 - acc: 0.1111\n",
      "Epoch 30/50\n",
      "11832/11832 [==============================] - 5s 438us/step - loss: 4.2221 - acc: 0.1110\n",
      "Epoch 31/50\n",
      "11832/11832 [==============================] - 5s 434us/step - loss: 4.1939 - acc: 0.1113\n",
      "Epoch 32/50\n",
      "11832/11832 [==============================] - 5s 410us/step - loss: 4.1664 - acc: 0.1111\n",
      "Epoch 33/50\n",
      "11832/11832 [==============================] - 6s 470us/step - loss: 4.1398 - acc: 0.1116\n",
      "Epoch 34/50\n",
      "11832/11832 [==============================] - 7s 614us/step - loss: 4.1139 - acc: 0.1120\n",
      "Epoch 35/50\n",
      "11832/11832 [==============================] - 8s 707us/step - loss: 4.0888 - acc: 0.1124\n",
      "Epoch 36/50\n",
      "11832/11832 [==============================] - 6s 499us/step - loss: 4.0643 - acc: 0.1129\n",
      "Epoch 37/50\n",
      "11832/11832 [==============================] - 5s 418us/step - loss: 4.0407 - acc: 0.1128\n",
      "Epoch 38/50\n",
      "11832/11832 [==============================] - 5s 440us/step - loss: 4.0176 - acc: 0.1125\n",
      "Epoch 39/50\n",
      "11832/11832 [==============================] - 5s 380us/step - loss: 3.9952 - acc: 0.1128\n",
      "Epoch 40/50\n",
      "11832/11832 [==============================] - 5s 423us/step - loss: 3.9734 - acc: 0.1138\n",
      "Epoch 41/50\n",
      "11832/11832 [==============================] - 6s 476us/step - loss: 3.9522 - acc: 0.1138\n",
      "Epoch 42/50\n",
      "11832/11832 [==============================] - 5s 432us/step - loss: 3.9316 - acc: 0.1138\n",
      "Epoch 43/50\n",
      "11832/11832 [==============================] - 5s 428us/step - loss: 3.9116 - acc: 0.1137\n",
      "Epoch 44/50\n",
      "11832/11832 [==============================] - 6s 517us/step - loss: 3.8921 - acc: 0.1142\n",
      "Epoch 45/50\n",
      "11832/11832 [==============================] - 6s 497us/step - loss: 3.8732 - acc: 0.1137\n",
      "Epoch 46/50\n",
      "11832/11832 [==============================] - 6s 492us/step - loss: 3.8549 - acc: 0.1138\n",
      "Epoch 47/50\n",
      "11832/11832 [==============================] - 5s 446us/step - loss: 3.8371 - acc: 0.1137\n",
      "Epoch 48/50\n",
      "11832/11832 [==============================] - 5s 397us/step - loss: 3.8197 - acc: 0.1145\n",
      "Epoch 49/50\n",
      "11832/11832 [==============================] - 5s 443us/step - loss: 3.8028 - acc: 0.1137\n",
      "Epoch 50/50\n",
      "11832/11832 [==============================] - 6s 495us/step - loss: 3.7865 - acc: 0.1143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1323f17f0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
